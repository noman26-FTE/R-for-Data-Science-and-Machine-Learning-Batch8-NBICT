var1= 500
print('var1')
print(var1)
var_2= mobile
var_2= 'mobile'
print(var_2)
assign('var5', 400)
print(var5)
if_=30
if2= 'mobile phone'
print(class(if_))
print(class(if2))
print(ls())
#find variables
print(ls(all.names = TRUE))
rm(var5)
print(ls(all.names = TRUE))
var5=300
print(ls(all.names = TRUE))
6*8
library(readxl)
data_MoST_24_25 <- read_excel("Desktop/Article/R/All works/data MoST 24-25.xlsx",
sheet = "Sheet4", range = "A1:AA87")
View(data_MoST_24_25)
library(readxl)
pc <- read_excel("Desktop/Article/R/All works/data MoST 24-25.xlsx",
sheet = "Sheet4", range = "A1:AA87")
View(pc)
library(devtools)
install.packages('devtools')
library(devtools)
library(devtools)
library(ggbiplot)
library(devtools)
library(ggbiplot)
library(ggplot2)
pca = prcomp(pc[-1],
center = TRUE,
scale. = TRUE)
pca$scale
print(pca)
summary(pca)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
View(g)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'horizontal',
legend.position = 'right')
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'horizontal',
legend.position = 'right')
print(g)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'vertical',
legend.position = 'top')
print(g)
rnorm(3, mean = 0.92, sd = 0.05)
rnorm(3, mean = 1.24, sd = 0.03)
rnorm(3, mean = 75.93, sd = 0.34)
rnorm(3, mean = 1.66, sd = 0.02)
rnorm(3, mean = 1.45, sd = 0.07)
rnorm(3, mean = 1.26, sd = 0.04)
rnorm(3, mean = 81.65, sd = 0.12)
rnorm(3, mean = 1.41, sd = 0.04)
rnorm(3, mean = 3.47, sd = 0.24)
rnorm(3, mean = 1.15, sd = 0.003)
rnorm(3, mean = 85.10, sd = 0.21)
rnorm(3, mean = 1.13, sd = 0.009)
setwd("~/Desktop/Article/R/All works/R-for-Data-Science-and-Machine-Learning-Batch8-NBICT/RDSML-Day-53 ðŸ‘‰ Support Vector Regression in R (Part-1)")
# Setup: packages and data loading
install.packages(c("e1071","ggplot2","dplyr"))
library(e1071)
library(ggplot2)
library(dplyr)
library(e1071)
library(ggplot2)
library(dplyr)
# Loading the dataset
dataset <- read.csv("day.csv")
bike <- dataset %>%
select(cnt, temp, atemp, hum, windspeed, season, yr, mnth,
holiday, weekday, workingday, weathersit)
str(bike)
# Convert categorical variables to factors
bike <- bike %>%
mutate(
season = factor(season),
yr = factor(yr),
mnth = factor(mnth),
holiday = factor(holiday),
weekday = factor(weekday),
workingday = factor(workingday),
weathersit = factor(weathersit)
)
str(bike)
# Train/Test Split
set.seed(123)
n <- nrow(bike)
indices <- seq_len(n)
train_idx <- sample(indices, size = 0.7 * n)
train_set <- bike[train_idx, ]
test_set <- bike[-train_idx, ]
num_cols = c("temp", "atemp", "hum", "windspeed")
train_means = sapply(train_set[, num_cols], mean)
train_sds = sapply(train_set[, num_cols], sd)
scale_num = function(df){
df[, num_cols] = sweep(df[, num_cols], 2, train_means, FUN = "-")
df[, num_cols] = sweep(df[, num_cols], 2, train_sds, FUN = "/")
return(df)
}
#Apply scaling
train_scaled = scale_num(train_set)
View(train_scaled)
test_scaled = scale_num(test_set)
View(test_scaled)
lm_model = lm(cnt ~ ., data = train_scaled)
summary(lm_model)
lm_pred = predict(lm_model, newdata = test_scaled)
summary(lm_pred)
lm_pred
rmse = function(actual, pred) sqrt(mean((actual-pred)^2))
lm_rmse = rmse(test_scaled$cnt, lm_pred)
lm_rmse
mae = function(actual, pred) mean(abs(actual - pred))
lm_mae = mae(test_scaled$cnt, lm_pred)
lm_mae
svr = svm(cnt ~ ., data = train_scaled, type = "eps-regression", kernel = "radial")
summary(svr)
svr = svm(cnt ~ ., data = train_scaled, type = "eps-regression", kernel = "linear")
summary(svr)
# Predicting on test set
svr_pred = predict(svr, newdata = test_scaled)
svr_pred
svr_model = svm(cnt ~ ., data = train_scaled, type = "eps-regression", kernel = "linear")
summary(svr_model)
# Predicting on test set
svr_pred = predict(svr_model, newdata = test_scaled)
svr_pred
#Evaluation metrics for SVR
#Calculating root mean squared error (RMSE)
svr_rmse = rmse(test_scaled$cnt, svr_pred)
svr_rmse
lm_rmse
svr_mae
svr_mae = mae(test_scaled$cnt, svr_pred)
svr_mae
lm_mae
#Comparing Linear Regression and SVR performance
comparison = data.frame(
Model = c("Linear Regression", "Support Vector Regression"),
RMSE = c(lm_rmse, svr_rmse),
MAE = c(lm_mae, svr_mae)
)
print(comparison)
lm(cnt ~ ., data = train_scaled)
summary(lm_model)
comparison = data.frame(
Model = c("Linear Regression", "Support Vector Regression"),
RMSE = c(lm_rmse, svr_rmse),
MAE = c(lm_mae, svr_mae)
)
print(comparison)
