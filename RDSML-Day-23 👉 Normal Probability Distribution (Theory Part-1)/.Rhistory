var1= 500
print('var1')
print(var1)
var_2= mobile
var_2= 'mobile'
print(var_2)
assign('var5', 400)
print(var5)
if_=30
if2= 'mobile phone'
print(class(if_))
print(class(if2))
print(ls())
#find variables
print(ls(all.names = TRUE))
rm(var5)
print(ls(all.names = TRUE))
var5=300
print(ls(all.names = TRUE))
6*8
library(readxl)
data_MoST_24_25 <- read_excel("Desktop/Article/R/All works/data MoST 24-25.xlsx",
sheet = "Sheet4", range = "A1:AA87")
View(data_MoST_24_25)
library(readxl)
pc <- read_excel("Desktop/Article/R/All works/data MoST 24-25.xlsx",
sheet = "Sheet4", range = "A1:AA87")
View(pc)
library(devtools)
install.packages('devtools')
library(devtools)
library(devtools)
library(ggbiplot)
library(devtools)
library(ggbiplot)
library(ggplot2)
pca = prcomp(pc[-1],
center = TRUE,
scale. = TRUE)
pca$scale
print(pca)
summary(pca)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
View(g)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'horizontal',
legend.position = 'right')
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'horizontal',
legend.position = 'right')
print(g)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'vertical',
legend.position = 'top')
print(g)
setwd("~/Desktop/Article/R/All works/R-for-Data-Science-and-Machine-Learning-Batch8-NBICT/RDSML-Day-23 ðŸ‘‰ Normal Probability Distribution (Theory Part-1)")
rnorm(10, mean = 67.03, sd = 0.56)
x = rnorm(10, mean = 67.03, sd = 0.56)
hist(x)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 67.18, sd = 0.54)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 67.16, sd = 0.72)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 71.2, sd = 0.41)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 67.18, sd = 0.54)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 66.84, sd = 0.61)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 1.03, sd = 0.13)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 1.49, sd = 0.21)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 1.44, sd = 0.10)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 0.60, sd = 0.01)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 1.49, sd = 0.21)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 1.40, sd = 0.50)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 11.25, sd = 0.39)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 11.88, sd = 0.52)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 10.12, sd = 0.35)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 8.75, sd = 0.53)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 11.88, sd = 0.52)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
rnorm(3, mean = 9.79, sd = 0.66)
rnorm(3, mean = 0.16, sd = 0.03)
rnorm(3, mean = 0.10, sd = 0.01)
rnorm(3, mean = 0.07, sd = 0.01)
rnorm(3, mean = 0.23, sd = 0.01)
rnorm(3, mean = 0.10, sd = 0.01)
rnorm(3, mean = 0.28, sd = 0.01)
rnorm(3, mean = 6.30, sd = 0.72)
rnorm(3, mean = 5.41, sd = 0.66)
rnorm(3, mean = 4.52, sd = 0.56)
rnorm(3, mean = 4.76, sd = 0.38)
rnorm(3, mean = 5.41, sd = 0.66)
rnorm(3, mean = 7.64, sd = 0.56)
rnorm(3, mean = 20.13, sd = 0.37)
rnorm(3, mean = 19.35, sd = 0.55)
rnorm(3, mean = 21.21, sd = 0.52)
rnorm(3, mean = 19.21, sd = 0.53)
rnorm(3, mean = 19.35, sd = 0.55)
rnorm(3, mean = 21.69, sd = 0.26)
rnorm(3, mean = 2.29, sd = 0.52)
rnorm(3, mean = 4.31, sd = 0.52)
rnorm(3, mean = 6.59, sd = 0.53)
rnorm(3, mean = 5.43, sd = 0.72)
rnorm(3, mean = 4.31, sd = 0.52)
rnorm(3, mean = 2.71, sd = 0.32)
rnorm(3, mean = 1.60, sd = 0.52)
rnorm(3, mean = 6.18, sd = 0.37)
rnorm(3, mean = 3.68, sd = 0.52)
rnorm(3, mean = 4.97, sd = 0.66)
rnorm(3, mean = 6.18, sd = 0.37)
rnorm(3, mean = 0.96, sd = 0.52)
rnorm(3, mean = 0.90, sd = 0.26)
rnorm(3, mean = 8.36, sd = 0.53)
rnorm(3, mean = 0.44, sd = 0.07)
rnorm(3, mean = 2.71, sd = 0.56)
rnorm(3, mean = 8.36, sd = 0.53)
rnorm(3, mean = 1.24, sd = 0.21)
rnorm(3, mean = 104.28, sd = 0.38)
rnorm(3, mean = 102.26, sd = 0.32)
rnorm(3, mean = 110.57, sd = 0.27)
rnorm(3, mean = 97.25, sd = 0.65)
rnorm(3, mean = 102.26, sd = 0.32)
rnorm(3, mean = 100.29, sd = 0.25)
#One way anova means to compare means of more than two groups
#If there are two groups we can use t-test
#Requirement for one way anova
#1. Dependent variable should be continuous
#2. Independent variable should be categorical with two or more groups
#No outliers are expected in the variable
#Homoscedasticity: The variance among the groups should be approximately equal
#We can use Levene's test to check for homoscedasticity
#We can use Shapiro-Wilk test to check for normality
#Importing the dataset
PlantGrowth <- PlantGrowth
View(PlantGrowth)
#Ho: All the group means are equal
#Ha: At least one group mean is different
#Importing the dplyr package
install.packages("dplyr")
library(dplyr)
#Computing the grpoup means and standard deviations, SE
stats = PlantGrowth %>%
group_by(group) %>%
summarise(
count = n(),
mean = mean(weight),
sd = sd(weight),
se = sd (weight)/sqrt(n()))
print(stats)
#Visualizing the data
#Creating groupwise boxplots to see the outliers
boxplot(weight ~ group,
data = PlantGrowth,
main = "PlantGrowth data",
ylab = "Dried weight of plants", col = "lightgray")
#From the boxplot we can see that there are no outliers
install.packages("ggpubr")
library(ggpubr)
#Creating groupwise violin plots to see the distribution of data
ggviolin(PlantGrowth, x = "group", y = "weight",
fill = "group", palette = "jco",
add = "boxplot", add.params = list(fill = "white")) +
stat_compare_means(label.y = 9)
#Another plot
#Dependent variable always goes to y-axis
#Visualizing the data using mean plot
ggline(PlantGrowth,
x = 'group',
y = 'weight',
add = c('mean_se', 'jitter'),
fill = 'group',)
#rUNNING THE ANOVA TEST
anova = aov(weight ~ group, data = PlantGrowth)
summary(anova)
#From the summary we can see that the p-value is less than 0.05
#So we reject the null hypothesis and accept the alternative hypothesis
#So we can say that at least one group mean is different
#rnorm(3, mean = 104.28, sd = 0.38)
summary(anova)
TukeyHSD(anova)
install.packages("car")
library(car)
leveneTest(weight ~ group, data = PlantGrowth)
#Homogeneity of variance test
plot(anova, 1)
#Homoscedasticity test
install.packages("car")
library(car)
levene.test(weight ~ group, data = PlantGrowth)
leveneTest(weight ~ group, data = PlantGrowth)
#If the variances are not equal we can use Welch ANOVA
oneway.test(weight ~ group, data = PlantGrowth)
#If the variances are not equal we can use Welch ANOVA
#oneway.test(weight ~ group, data = PlantGrowth)
#Pairwise t test with no assumption of equal variances
pairwise.t.test(PlantGrowth$weight, PlantGrowth$group)
#If the variances are not equal we can use Welch ANOVA
#oneway.test(weight ~ group, data = PlantGrowth)
#Pairwise t test with no assumption of equal variances
pairwise.t.test(PlantGrowth$weight, PlantGrowth$group,p.adjust.method = "BH", pool.sd = FALSE)
#Normality test
plot(anova, 2)
shapiro.test(residuals(anova))
#Extracting residuals
aov_res = residuals(object = anova)
aov_res
shapiro.test(aov_res)
#If the data is not normally distributed we can use Kruskal-Wallis test
kruskal.test(weight ~ group, data = PlantGrowth)
#Pairwise wilcoxon test
pairwise.wilcox.test(PlantGrowth$weight, PlantGrowth$group, p.adjust.method = "BH")
