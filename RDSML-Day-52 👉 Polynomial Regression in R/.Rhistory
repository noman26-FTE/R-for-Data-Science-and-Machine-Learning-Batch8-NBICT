var1= 500
print('var1')
print(var1)
var_2= mobile
var_2= 'mobile'
print(var_2)
assign('var5', 400)
print(var5)
if_=30
if2= 'mobile phone'
print(class(if_))
print(class(if2))
print(ls())
#find variables
print(ls(all.names = TRUE))
rm(var5)
print(ls(all.names = TRUE))
var5=300
print(ls(all.names = TRUE))
6*8
library(readxl)
data_MoST_24_25 <- read_excel("Desktop/Article/R/All works/data MoST 24-25.xlsx",
sheet = "Sheet4", range = "A1:AA87")
View(data_MoST_24_25)
library(readxl)
pc <- read_excel("Desktop/Article/R/All works/data MoST 24-25.xlsx",
sheet = "Sheet4", range = "A1:AA87")
View(pc)
library(devtools)
install.packages('devtools')
library(devtools)
library(devtools)
library(ggbiplot)
library(devtools)
library(ggbiplot)
library(ggplot2)
pca = prcomp(pc[-1],
center = TRUE,
scale. = TRUE)
pca$scale
print(pca)
summary(pca)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
View(g)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'horizontal',
legend.position = 'right')
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'horizontal',
legend.position = 'right')
print(g)
g = ggbiplot(pca,
obs.scale = 1,
var.scale = 1,
groups = pc$water,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)+
scale_color_discrete(name = '') +
theme(legend.direction = 'vertical',
legend.position = 'top')
print(g)
rnorm(3, mean = 0.92, sd = 0.05)
rnorm(3, mean = 1.24, sd = 0.03)
rnorm(3, mean = 75.93, sd = 0.34)
rnorm(3, mean = 1.66, sd = 0.02)
rnorm(3, mean = 1.45, sd = 0.07)
rnorm(3, mean = 1.26, sd = 0.04)
rnorm(3, mean = 81.65, sd = 0.12)
rnorm(3, mean = 1.41, sd = 0.04)
rnorm(3, mean = 3.47, sd = 0.24)
rnorm(3, mean = 1.15, sd = 0.003)
rnorm(3, mean = 85.10, sd = 0.21)
rnorm(3, mean = 1.13, sd = 0.009)
setwd("~/Desktop/Article/R/All works/R-for-Data-Science-and-Machine-Learning-Batch8-NBICT/RDSML-Day-52 ðŸ‘‰ Polynomial Regression in R")
setwd("~/Desktop/Article/R/All works/R-for-Data-Science-and-Machine-Learning-Batch8-NBICT/RDSML-Day-52 ðŸ‘‰ Polynomial Regression in R")
# Importing the dataset
dataset = read.csv('polynom_data.csv')
View(dataset)
attach(dataset)
#Plot the dataset
plot(x, y)
#Plot the dataset
plot(x, y, main = 'Scatter Plot of Dataset', xlab = 'Independent Variable (X)', ylab = 'Dependent Variable (Y)', pch = 19, col = 'blue')
#Plot the dataset
plot(x, y, main = 'Polynomial Regression Example', xlab = 'Independent Variable (X)', ylab = 'Dependent Variable (Y)', pch = 19, col = 'blue')
#Fit a quadratic (degree 2) polynomial regression model to the dataset
polynom_model = lm(y ~ poly(x, 2, raw = TRUE), data = dataset)
polynom_model
summary(polynom_model)
polynom_model =
#summary of the model
summary(polynom_model)
#summary of the model
summary(polynom_model)
polynom_model = lm(y ~ poly(x, 2, raw = TRUE), data = dataset)
#summary of the model
summary(polynom_model)
#Create new data for prediction
x_new = seq(min(x), max(x), length.out = 100)
x_new = seq(min(x), max(x), length.out = 100)
x_new
x_new= data.frame(x = x_new)
x_new
y_pred = predict(polynom_model, newdata = x_new)
y_pred
pred_data = data.frame(x_new, y_pred)
View(pred_data)
pred_data = data.frame(x_new, y_pred)
x_new = seq(min(x), max(x), length.out = 100)
y_pred = predict(polynom_model, newdata = data.frame(x=x_new))
pred_data = data.frame(x_new, y_pred)
View(pred_data)
lines(x_new, y_pred, col = 'blue', lwd = 2)
ggplot() +
geom_point(aes(x = x, y = y), color = 'blue') +
geom_line(aes(x = x_new, y = y_pred), color = 'blue', size = 1) +
ggtitle('Polynomial Regression Results') +
xlab('Independent Variable (X)') +
ylab('Dependent Variable (Y)') +
theme_minimal()
#Visualizing the Polynomial Regression results (for higher resolution and smoother curve)
library(ggplot2)
ggplot() +
geom_point(aes(x = x, y = y), color = 'blue') +
geom_line(aes(x = x_new, y = y_pred), color = 'blue', size = 1) +
ggtitle('Polynomial Regression Results') +
xlab('Independent Variable (X)') +
ylab('Dependent Variable (Y)') +
theme_minimal()
polynom_model_cubic = lm(y ~ poly(x, 3, raw = TRUE), data = dataset)
summary(polynom_model_cubic)
lines(x_new, predict(polynom_model_cubic, newdata = data.frame(x=x_new)), col = 'red', lwd = 1)
lines(x_new, predict(polynom_model_cubic, newdata = data.frame(x=x_new)), col = 'red', lwd = 1, lty = 2)
lines(x_new,
predict(polynom_model_cubic, newdata = data.frame(x=x_new)),
col = 'red', lwd = 1, lty = 2)
lines(x_new,
predict(polynom_model_cubic, newdata = data.frame(x=x_new)),
col = 'red', lwd = 2, lty = 2)
polynom_model_cubic = lm(y ~ poly(x, 3, raw = TRUE), data = dataset)
summary(polynom_model_cubic)
#Add fitted curve to the plot
lines(x_new,
predict(polynom_model_cubic, newdata = data.frame(x=x_new)),
col = 'red', lwd = 2, lty = 2)
polynom_model_cubic = lm(y ~ poly(x, 3, raw = TRUE))
summary(polynom_model_cubic)
#Add fitted curve to the plot
lines(x_new,
predict(polynom_model_cubic, newdata = data.frame(x=x_new)),
col = 'red', lwd = 2, lty = 2)
#wHAT IS POLINOMIAL REGRESSION?
#Polynomial regression is a type of regression analysis in which the relationship between the independent variable (X) and the dependent variable (Y) is modeled as an nth degree polynomial. It is used when the data shows a curvilinear relationship, meaning that the change in Y is not constant for a unit change in X.
# equation of polynomial regression:
# Y = b0 + b1*X + b2*X^2 + b3*X^3 + ... + bn*X^n
# Importing the dataset
dataset = read.csv('polynom_data.csv')
attach(dataset)
#Plot the dataset
plot(x, y, main = 'Polynomial Regression Example', xlab = 'Independent Variable (X)', ylab = 'Dependent Variable (Y)', pch = 19, col = 'blue')
#Fit a quadratic (degree 2) polynomial regression model to the dataset. #quadratic (degree 2) means we are fitting a polynomial of degree 2
#y = a + b1*x + b2*x^2
polynom_model = lm(y ~ poly(x, 2, raw = TRUE), data = dataset)
#summary of the model
summary(polynom_model)
#Create new data for prediction
x_new = seq(min(x), max(x), length.out = 100)
y_pred = predict(polynom_model, newdata = data.frame(x=x_new))
pred_data = data.frame(x_new, y_pred)
#Add fitted curve to the plot
lines(x_new, y_pred, col = 'blue', lwd = 2)
#Visualizing the Polynomial Regression results (for higher resolution and smoother curve)
library(ggplot2)
ggplot() +
geom_point(aes(x = x, y = y), color = 'blue') +
geom_line(aes(x = x_new, y = y_pred), color = 'blue', size = 1) +
ggtitle('Polynomial Regression Results') +
xlab('Independent Variable (X)') +
ylab('Dependent Variable (Y)') +
theme_minimal()
#Fit a cubic (degree 3) polynomial regression model to the dataset. #y = a + b1*x + b2*x^2 + b3*x^3. How much degrre we have to fit the model
polynom_model3 = lm(y ~ poly(x, 3, raw = TRUE))
summary(polynom_model3)
lines(x_new,
predict(polynom_model3, newdata = data.frame(x=x_new)),
col = 'red', lwd = 2, lty = 2)
polynom_model3 = lm(y ~ poly(x, 3, raw = TRUE))
summary(polynom_model3)
lines(x_new,
predict(polynom_model3, newdata = data.frame(x=x_new)),
col = 'red', lwd = 2, lty = 2
lines(x_new,
polynom_model3 = lm(y ~ poly(x, 3, raw = TRUE))
summary(polynom_model3)
lines(x_new,
predict(polynom_model3, newdata = data.frame(x=x_new)),
col = 'red', lwd = 5, lty = 2)
dataset <- read.csv("polynom_data.csv")
attach(dataset)
# Plot the data
plot(x, y, main = "Polynomial Regression Example", pch = 19)
# Fit a quadratic (degree 2) polynomial regression
polynom_model <- lm(y ~ poly(x, 2, raw = TRUE))
# View the model summary
summary(polynom_model)
# Create new data for prediction
x_new <- seq(min(x), max(x), length.out = 100)
# x_new <- data.frame(x_new)
y_pred <- predict(polynom_model, newdata = data.frame(x = x_new))
pred_data <- data.frame(x_new, y_pred)
# Add fitted curve to the plot
lines(x_new, y_pred, col = "blue", lwd = 2)
# Fit a cubic (degree 3) polynomial regression
polynom_model3 <- lm(y ~ poly(x, 3, raw = TRUE))
summary(polynom_model3)
lines(x_new,
predict(polynom_model3, newdata = data.frame(x = x_new)),
col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("Degree2", "Degree3"),
col = c("blue", "red"),
lty = c(1, 2),
lwd = 2)
lines(x_new,
predict(polynom_model3, newdata = data.frame(x = x_new)),
col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("Degree2", "Degree3"),
col = c("blue", "red"),
lty = c(1, 2),
lwd = 2)
setwd("~/Desktop/Article/R/All works/R-for-Data-Science-and-Machine-Learning-Batch8-NBICT/RDSML-Day-52 ðŸ‘‰ Polynomial Regression in R")
setwd("~/Desktop/Article/R/All works/R-for-Data-Science-and-Machine-Learning-Batch8-NBICT/RDSML-Day-52 ðŸ‘‰ Polynomial Regression in R")
dataset <- read.csv("polynom_data.csv")
attach(dataset)
# Plot the data
plot(x, y, main = "Polynomial Regression Example", pch = 19)
# Fit a quadratic (degree 2) polynomial regression
polynom_model <- lm(y ~ poly(x, 2, raw = TRUE))
# View the model summary
summary(polynom_model)
# Create new data for prediction
x_new <- seq(min(x), max(x), length.out = 100)
# x_new <- data.frame(x_new)
y_pred <- predict(polynom_model, newdata = data.frame(x = x_new))
pred_data <- data.frame(x_new, y_pred)
# Add fitted curve to the plot
lines(x_new, y_pred, col = "blue", lwd = 2)
polynom_model3 <- lm(y ~ poly(x, 3, raw = TRUE))
summary(polynom_model3)
lines(x_new,
predict(polynom_model3, newdata = data.frame(x = x_new)),
col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("Degree2", "Degree3"),
col = c("blue", "red"),
lty = c(1, 2),
lwd = 2)
ggplot() +
geom_point(aes(x = x, y = y), color = "blue") +
geom_line(aes(x = x_new, y = y_pred), color = "blue", size = 1) +
ggtitle("Polynomial Regression Results") +
xlab("Independent Variable (X)") +
ylab("Dependent Variable (Y)") +
theme_minimal()
legend("topright", legend = c("Degree2", "Degree3"),
col = c("blue", "red"),
lty = c(1, 2),
lwd = 2)
polynom_model3 <- lm(y ~ poly(x, 3, raw = TRUE))
summary(polynom_model3)
lines(x_new,
predict(polynom_model3, newdata = data.frame(x = x_new)),
col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("Degree2", "Degree3"),
col = c("blue", "red"),
lty = c(1, 2),
lwd = 2)
#Instructor Repository
# Importing the dataset
dataset <- read.csv("polynom_data.csv")
attach(dataset)
# Plot the data
plot(x, y, main = "Polynomial Regression Example", pch = 19)
# Fit a quadratic (degree 2) polynomial regression
polynom_model <- lm(y ~ poly(x, 2, raw = TRUE))
# View the model summary
summary(polynom_model)
# Create new data for prediction
x_new <- seq(min(x), max(x), length.out = 100)
# x_new <- data.frame(x_new)
y_pred <- predict(polynom_model, newdata = data.frame(x = x_new))
pred_data <- data.frame(x_new, y_pred)
# Add fitted curve to the plot
lines(x_new, y_pred, col = "blue", lwd = 2)
# Fit a cubic (degree 3) polynomial regression
polynom_model3 <- lm(y ~ poly(x, 3, raw = TRUE))
summary(polynom_model3)
lines(x_new,
predict(polynom_model3, newdata = data.frame(x = x_new)),
col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("Degree2", "Degree3"),
col = c("blue", "red"),
lty = c(1, 2),
lwd = 2)
legend("topright", legend = c("Degree2", "Degree3"),
col = c("blue", "red"),
lty = c(1, 2),
lwd = 2)
# Fit a cubic (degree 4) polynomial regression
polynom_model4 <- lm(y ~ poly(x, 4, raw = TRUE))
summary(polynom_model4)
lines(x_new,
predict(polynom_model4, newdata = data.frame(x = x_new)),
col = "orange", lwd = 3, lty = 3)
lines(x_new,
predict(polynom_model4, newdata = data.frame(x = x_new)),
col = "orange", lwd = 3, lty = 3)
lines(x_new,
predict(polynom_model4, newdata = data.frame(x = x_new)),
col = "orange", lwd = 2, lty = 2)
legend("topright", legend = c("Degree2", "Degree3", "Degree4"),
col = c("blue", "red"),
lty = c(1, 2),
lwd = 2)
legend("topright", legend = c("Degree2", "Degree3", "Degree4"),
col = c("blue", "red", "orange"),
lty = c(1, 2),
lwd = 2)
polynom_model4 <- lm(y ~ poly(x, 4, raw = TRUE))
summary(polynom_model4)
lines(x_new,
predict(polynom_model4, newdata = data.frame(x = x_new)),
col = "orange", lwd = 2, lty = 2)
#Instructor Repository
# Importing the dataset
dataset <- read.csv("polynom_data.csv")
attach(dataset)
# Plot the data
plot(x, y, main = "Polynomial Regression Example", pch = 19)
# Fit a quadratic (degree 2) polynomial regression
polynom_model <- lm(y ~ poly(x, 2, raw = TRUE))
# View the model summary
summary(polynom_model)
# Create new data for prediction
x_new <- seq(min(x), max(x), length.out = 100)
# x_new <- data.frame(x_new)
y_pred <- predict(polynom_model, newdata = data.frame(x = x_new))
pred_data <- data.frame(x_new, y_pred)
# Add fitted curve to the plot
lines(x_new, y_pred, col = "blue", lwd = 2)
# Fit a cubic (degree 3) polynomial regression
polynom_model3 <- lm(y ~ poly(x, 3, raw = TRUE))
summary(polynom_model3)
lines(x_new,
predict(polynom_model3, newdata = data.frame(x = x_new)),
col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("Degree2", "Degree3"),
col = c("blue", "red"),
lty = c(1, 2),
lwd = 2)
# Fit a cubic (degree 4) polynomial regression
polynom_model4 <- lm(y ~ poly(x, 4, raw = TRUE))
summary(polynom_model4)
lines(x_new,
predict(polynom_model4, newdata = data.frame(x = x_new)),
col = "orange", lwd = 2, lty = 2)
legend("topright", legend = c("Degree2", "Degree3", "Degree4"),
col = c("blue", "red", "orange"),
lty = c(1, 2),
lwd = 2)
polynom_model5 <- lm(y ~ poly(x, 5, raw = TRUE))
summary(polynom_model5)
lines(x_new,
predict(polynom_model5, newdata = data.frame(x = x_new)),
col = "grey", lwd = 2, lty = 2)
legend("topright", legend = c("Degree2", "Degree3", "Degree4", "Degree5"),
col = c("blue", "red", "orange", "grey"),
lty = c(1, 2),
lwd = 2)
